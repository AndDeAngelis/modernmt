#!/bin/bash

declare timer_time

function timer_start {
	timer_time=$(date +%s)
}

function timer_stop {
	timer_time_stop=$(date +%s)
	timer_elapsed_ms=$(( $timer_time_stop - $timer_time ))

	echo -n "$timer_elapsed_ms"
}

function linfo {
	if [ $# -eq 2 ]; then
		echo $1 "INFO: $2"
	else
		echo "INFO: $1"
	fi
}

function lwarn {
	if [ $# -eq 2 ]; then
		echo $1 "WARNING: $2"
	else
		echo "WARNING: $1"
	fi
}

function lerr {
	if [ $# -eq 2 ]; then
		>&2 echo $1 "ERROR: $2"
	else
		>&2 echo "ERROR: $1"
	fi
}

function printhelp {
	echo "Usage:"
	echo "    $0 -i <train-data-directory> -s <source-language> -t <target-language> [-n <engine-name>] [-o <lm-order>] [--debug]"
	echo
	echo "Default values:"
	echo "    engine-name: default"
	echo "    lm-order: 5"
	echo
	echo "Example of usage:"
	echo "    create-engine -i ./example/train-data -s en -t it"
	echo
}

# Usage:
#	create-engine -i <train-data-directory> -s <source-language> -t <target-language> [-n <engine-name>] [-o <lm-order>] [--debug]
#	
# Train data directory notes:
#	Train data must be organized in plaint text file pairs: one pair for each corpus.
#	Each pair is made of two parallel text files, one for source language and one for target language, so for example
#	if you have 3 corpora (corpus-a, corpus-b and corpus-c) with source language "en" and target language "it", your data directory
#	should look like this:
#
#	/path/to/train/data/
#		corpus-a.en
#		corpus-a.it
#		corpus-b.en
#		corpus-b.it
#		corpus-c.en
#		corpus-c.it
#

cpu_cores=$(grep -c ^processor /proc/cpuinfo)

arg_lm_order=5
arg_train_data=
arg_source_lang=
arg_target_lang=
arg_debug=
arg_engine="default"

# Args parsing

while [[ $# > 0 ]]; do
	key="$1"

	case $key in
	-i|--input)
		arg_train_data="$2"
		shift
	;;
	-s|--source-lang)
		arg_source_lang="$2"
		shift
	;;
	-t|--target-lang)
		arg_target_lang="$2"
		shift
	;;
	-n|--name)
		arg_engine="$2"
		shift
	;;
	-o|--lm-order)
		arg_lm_order="$2"
		shift
	;;
	--debug)
		arg_debug=1
	;;
	*)
		# unknown option
	;;
	esac

	shift
done

# Args validation

if [ -z "$arg_train_data" ]; then
	lerr "missing parameter 'input' (-i, --input)"
	printhelp
	exit 1
fi
if [ ! -d "$arg_train_data" ]; then
	lerr "'input' parameter is not a valid directory: $arg_train_data"
	printhelp
	exit 2
fi

if [ -z "$arg_source_lang" ]; then
	lerr "missing parameter 'source language' (-s, --source-lang)"
	printhelp
	exit 1
fi

if [ -z "$arg_target_lang" ]; then
	lerr "missing parameter 'target language' (-t, --target-lang)"
	printhelp
	exit 1
fi

echo
echo "========== INPUT VALIDATION =========="
echo

linfo -n "(1 of 2) Checking source corpora...                              "
timer_start

for source_file in $( find $arg_train_data -type f -name "*.$arg_source_lang" ); do
	dir=$(dirname "$source_file")
	filename=$(basename "$source_file")
	filename="${filename%.*}"

	target_file="$dir/$filename.$arg_target_lang"
	
	if [ ! -f "$target_file" ]; then
		lerr "invalid train data, missing parallel corpus '$target_file'"
		exit 3
	fi

	sflc=$(wc -l < $source_file)
	tflc=$(wc -l < $target_file)

	if [ "$sflc" != "$tflc" ]; then
		lerr "invalid parellel files, line count does not match for corpus '$filename'"
		exit 4
	fi
done

echo "DONE (in $(timer_stop)s)"

linfo -n "(2 of 2) Checking target corpora...                              "
timer_start

for target_file in $( find $arg_train_data -type f -name "*.$arg_target_lang" ); do
	dir=$(dirname "$target_file")
	filename=$(basename "$target_file")
	filename="${filename%.*}"

	source_file="$dir/$filename.$arg_source_lang"
	
	if [ ! -f "$source_file" ]; then
		lerr "invalid train data, missing parallel corpus '$source_file'"
		exit 3
	fi
done

echo "DONE (in $(timer_stop)s)"

# Import environment

__home=$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )
source $__home/scripts/env.sh $arg_engine

# Clean up data

rm -rf $engine_dir
mkdir -p $engine_runtime_dir
mkdir -p $engine_temp_dir
mkdir -p $engine_log_dir
mkdir -p $engine_build_log_dir
mkdir -p $engine_context_analyzer_dir
mkdir -p $engine_context_analyzer_index_dir
mkdir -p $engine_moses_dir
mkdir -p $engine_models_dir

function cleanup_temp {
	if [ -z "$arg_debug" ]; then
		rm -rf $engine_temp_dir
	fi
}

trap cleanup_temp EXIT

# ================================================================================
# Step 0 - Data cleanup
# ================================================================================

echo
echo "=========== SETUP STARTED ============"
echo
echo "Creation of engine: $arg_engine"
echo

# Tokenizing

tokenizer=$tokenizer_home/tokenize.sh
tokenizer_out=$engine_temp_dir/corpus.tokenized
tokenizer_log=$engine_build_log_dir/tokenizer.log

mkdir -p $tokenizer_out

linfo -n "(1 of 5) Corpus tokenization...                                  "
timer_start

iteration_count=0
max_threads=$(( $cpu_cores * 2 / 3 ))

if [ $max_threads -lt 1 ]; then
	max_threads=1
fi

for corpus in $( find $arg_train_data -type f \( -name "*.$arg_target_lang" -or -name "*.$arg_source_lang" \) | xargs du | sort -rn | awk '{print $2}'); do
	filename=$(basename "$corpus")
	lang="${filename##*.}"

	if [ $iteration_count -gt $max_threads ]; then
		wait
		iteration_count=0
	else
		iteration_count=$(( $iteration_count + 1 ))
	fi

	cat $corpus | $tokenizer $lang > $tokenizer_out/$filename 2>> $tokenizer_log &
done

wait

echo "DONE (in $(timer_stop)s)"

# Cleaning

corpus_cleaner=$corpus_cleaner_home/clean.sh
corpus_cleaner_out=$engine_temp_dir/corpus.clean
corpus_cleaner_log=$engine_build_log_dir/cleaner.log

mkdir -p $corpus_cleaner_out

linfo -n "(2 of 5) Corpus cleaning...                                      "
timer_start

for source_file in $( find $tokenizer_out -type f -name "*.$arg_source_lang" ); do
	dir=$(dirname "$source_file")
	filename=$(basename "$source_file")
	filename="${filename%.*}"

	file=$dir/$filename
	out=$corpus_cleaner_out/$filename

	$corpus_cleaner "$file" "$arg_source_lang" "$arg_target_lang" "$out" 2>> $corpus_cleaner_log
done

echo "DONE (in $(timer_stop)s)"

# ================================================================================
# Step 1 - Create Lucene index for context analysis
# ================================================================================

context_analyzer_log=$engine_build_log_dir/context-analyzer.log
context_analyzer_url="http://$CONTEXT_ANALYZER_PLACEHOLDER/context"

linfo -n "(3 of 5) Training Context Analyzer...                            "
timer_start

java -cp $context_analyzer_home/context-analyzer.jar net.translated.contextanalyzer.cli.CreateIndex -i "$engine_context_analyzer_index_dir" -c "$corpus_cleaner_out" >> $context_analyzer_log 2>&1

echo "DONE (in $(timer_stop)s)"

# ================================================================================
# Step 2 - Train language model
# ================================================================================

lm_target_model=$engine_models_dir/$arg_target_lang.blm
lm_target_model_log=$engine_build_log_dir/target-lm.log
lm_temp=$engine_temp_dir/lm

mkdir -p $lm_temp

linfo -n "(4 of 5) Creating target language model...                       "
timer_start
$language_model_home/lm.sh "$corpus_cleaner_out/*.$arg_target_lang" "$lm_target_model" $arg_lm_order "$lm_temp" >> $lm_target_model_log 2>&1
echo "DONE (in $(timer_stop)s)"

# ================================================================================
# Step 3 - Train and launch Moses with Suffix Arrays
# ================================================================================

# Create decoder-setup.cfg

moses_makefile=$moses_home/Makefile.setup-decoder
moses_decoder_setup=$engine_temp_dir/decoder-setup.cfg
moses_temp=$engine_temp_dir/moses
moses_log=$engine_build_log_dir/moses.log

echo	"L1 = $arg_source_lang"					>  $moses_decoder_setup
echo	"L2 = $arg_target_lang"					>> $moses_decoder_setup

echo	"lm.path = $lm_target_model"			>> $moses_decoder_setup
echo	"lm.type = IRSTLM"						>> $moses_decoder_setup
echo	"lm.order = $arg_lm_order"				>> $moses_decoder_setup

echo	"DATADIR = $corpus_cleaner_out"			>> $moses_decoder_setup
echo	"PREFIX = $engine_moses_dir"			>> $moses_decoder_setup
echo	"MOSES_BIN = $moses_home/bin"			>> $moses_decoder_setup
echo	"WDIR = $moses_temp"					>> $moses_decoder_setup

echo	"bias_url = $context_analyzer_url"		>> $moses_decoder_setup
echo	"bias_srclang = $arg_source_lang"		>> $moses_decoder_setup

echo	"zipped = "								>> $moses_decoder_setup
echo	"zipper = "								>> $moses_decoder_setup
echo	"zcat = cat"							>> $moses_decoder_setup

# Start makefile

linfo -n "(5 of 5) Setting up Moses decoder with Suffix Arrays...          "
timer_start
export LC_ALL=C
make -f $moses_makefile decoder_setup="$moses_decoder_setup" >> $moses_log 2>&1
echo "DONE (in $(timer_stop)s)"



echo
echo "========== SETUP COMPLETED ==========="
echo
echo "You can start/stop the server:"
echo "      ./server start|stop|status "
echo "if you want to explicity set the service ports you can use:"
echo "      ./server start [context-analyzer-port moses-decoder-port rest-api-port]"
echo
echo "Once you have started the service, you can try it via API:"
echo "      curl \"http://localhost:7533/?text=jobs&context=parliament\""
echo "or via CLI:"
echo "      ./translate \"jobs\" \"parliament\""
echo
echo

















